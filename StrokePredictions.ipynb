{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Healthcare Dataset Stroke Data\n",
    "\n",
    "According to the World Health Organization, ischaemic heart disease and stroke are the worldâ€™s biggest killers. \n",
    "The goal of this project is to predict the stroke probability using the given information of patients. \n",
    "It is a binary classification problem, hence we will try to predict the probability of an observation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing packages\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql as sparksql\n",
    "from pyspark.sql.functions import mean\n",
    "from pyspark.ml.feature import VectorAssembler,OneHotEncoder,StringIndexer,OneHotEncoderEstimator\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator, BinaryClassificationEvaluator\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.mllib.linalg import Vectors\n",
    "from pyspark.ml.linalg import Vectors, VectorUDT\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('stroke').getOrCreate() #starting Spark session\n",
    "train = spark.read.csv('train_2v.csv', inferSchema=True,header=True) # reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- age: double (nullable = true)\n",
      " |-- hypertension: integer (nullable = true)\n",
      " |-- heart_disease: integer (nullable = true)\n",
      " |-- ever_married: string (nullable = true)\n",
      " |-- work_type: string (nullable = true)\n",
      " |-- Residence_type: string (nullable = true)\n",
      " |-- avg_glucose_level: double (nullable = true)\n",
      " |-- bmi: double (nullable = true)\n",
      " |-- smoking_status: string (nullable = true)\n",
      " |-- stroke: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.printSchema() # displaying schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|stroke|count|\n",
      "+------+-----+\n",
      "|     1|  783|\n",
      "|     0|42617|\n",
      "+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.groupBy('stroke').count().show() # displaying number of entries under each category of predictor variable 'stroke'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observation\n",
    "\n",
    "From the table above, we can see that this is an imbalanced dataset, where the number of observations belonging to one class is significantly lower than those belonging to the other classes. In this case, the predictive model could be biased and inaccurate.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create DataFrame as a temporary view\n",
    "train.createOrReplaceTempView('table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---------------+\n",
      "|    work_type|work_type_count|\n",
      "+-------------+---------------+\n",
      "|      Private|            441|\n",
      "|Self-employed|            251|\n",
      "|     Govt_job|             89|\n",
      "|     children|              2|\n",
      "+-------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# checking what type of job is more likely to have stroke patients\n",
    "spark.sql(\"SELECT work_type, count(work_type) as work_type_count FROM table WHERE stroke == 1 \\\n",
    "          GROUP BY work_type ORDER BY work_type_count DESC\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------+-------------------+\n",
      "|gender|count_gender|            percent|\n",
      "+------+------------+-------------------+\n",
      "|Female|       25665|  59.13594470046083|\n",
      "| Other|          11|0.02534562211981567|\n",
      "|  Male|       17724|  40.83870967741935|\n",
      "+------+------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# checking number and percentage of entries of each gender\n",
    "spark.sql(\"SELECT gender, count(gender) as count_gender, \\\n",
    "           count(gender)*100/sum(count(gender)) over() as percent FROM table GROUP BY gender\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------+----------------+\n",
      "|gender|count(gender)|      percentage|\n",
      "+------+-------------+----------------+\n",
      "|  Male|          352|1.98600767321146|\n",
      "+------+-------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# checking number and percentage of males having strokes\n",
    "spark.sql(\"SELECT gender, count(gender), \\\n",
    "         (COUNT(gender) * 100.0) /(SELECT count(gender) FROM table WHERE gender == 'Male') \\\n",
    "          as percentage FROM table WHERE stroke = '1' and gender = 'Male' GROUP BY gender\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------+----------------+\n",
      "|gender|count(gender)|      percentage|\n",
      "+------+-------------+----------------+\n",
      "|Female|          431|1.67932982661212|\n",
      "+------+-------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# checking number and percentage of females having strokes\n",
    "spark.sql(\"SELECT gender, count(gender), \\\n",
    "         (COUNT(gender) * 100.0) /(SELECT count(gender) FROM table WHERE gender == 'Female') \\\n",
    "          as percentage FROM table WHERE stroke = '1' and gender = 'Female' GROUP BY gender\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------+\n",
      "| age|age_count|\n",
      "+----+---------+\n",
      "|79.0|       70|\n",
      "|78.0|       57|\n",
      "|80.0|       49|\n",
      "|81.0|       43|\n",
      "|82.0|       36|\n",
      "|70.0|       25|\n",
      "|74.0|       24|\n",
      "|77.0|       24|\n",
      "|76.0|       24|\n",
      "|67.0|       23|\n",
      "|75.0|       23|\n",
      "|72.0|       21|\n",
      "|68.0|       20|\n",
      "|59.0|       20|\n",
      "|69.0|       20|\n",
      "|71.0|       19|\n",
      "|57.0|       19|\n",
      "|63.0|       18|\n",
      "|65.0|       18|\n",
      "|66.0|       17|\n",
      "+----+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# checking if age has a relation to the number of stroke patients\n",
    "spark.sql(\"SELECT age, count(age) as age_count FROM table WHERE stroke == 1 \\\n",
    "           GROUP BY age ORDER BY age_count DESC\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "708"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking how many patients over the age of 50 have strokes\n",
    "train.filter((train['stroke'] == 1) & (train['age'] > '50')).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill in missing values for smoking_status as 'No Info'\n",
    "train_f = train.na.fill('No Info', subset=['smoking_status']) \n",
    "\n",
    "# fill in miss values for BMI with mean of all bmi values\n",
    "mean = train_f.select(mean(train_f['bmi'])).collect()\n",
    "mean_bmi = mean[0][0]\n",
    "train_f = train_f.na.fill(mean_bmi,['bmi'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of ML algorithms cannot work directly with categorical data. The encoding allows algorithms which expect continuous features to use categorical features. We convert them into vectors using the following steps:\n",
    "\n",
    "Categorical -> StringIndexer -> OneHotEncoder -> VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_indexer = StringIndexer(inputCol = 'gender', outputCol = 'genderIndex')\n",
    "gender_encoder = OneHotEncoder(inputCol = 'genderIndex', outputCol = 'genderVec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ever_married_indexer = StringIndexer(inputCol = 'ever_married', outputCol = 'ever_marriedIndex')\n",
    "ever_married_encoder = OneHotEncoder(inputCol = 'ever_marriedIndex', outputCol = 'ever_marriedVec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "work_type_indexer = StringIndexer(inputCol = 'work_type', outputCol = 'work_typeIndex')\n",
    "work_type_encoder = OneHotEncoder(inputCol = 'work_typeIndex', outputCol = 'work_typeVec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "Residence_type_indexer = StringIndexer(inputCol = 'Residence_type', outputCol = 'Residence_typeIndex')\n",
    "Residence_type_encoder = OneHotEncoder(inputCol = 'Residence_typeIndex', outputCol = 'Residence_typeVec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "smoking_status_indexer = StringIndexer(inputCol = 'smoking_status', outputCol = 'smoking_statusIndex')\n",
    "smoking_status_encoder = OneHotEncoder(inputCol = 'smoking_statusIndex', outputCol = 'smoking_statusVec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypertension_indexer = StringIndexer(inputCol = 'hypertension', outputCol = 'hypertensionIndex')\n",
    "hypertension_encoder = OneHotEncoder(inputCol = 'hypertensionIndex', outputCol = 'hypertensionVec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_disease_indexer = StringIndexer(inputCol = 'heart_disease', outputCol = 'heart_diseaseIndex')\n",
    "heart_disease_encoder = OneHotEncoder(inputCol = 'heart_diseaseIndex', outputCol = 'heart_diseaseVec')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating an assembler using VectorAssembler to combine columns into a single vector column to train ML model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine Learning Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(inputCols=['genderVec',\n",
    "                                       'age',\n",
    "                                       'hypertensionVec',\n",
    "                                       'heart_diseaseVec',\n",
    "                                       'ever_marriedVec',\n",
    "                                       'work_typeVec',\n",
    "                                       'Residence_typeVec',\n",
    "                                       'avg_glucose_level',\n",
    "                                       'bmi',\n",
    "                                       'smoking_statusVec'],outputCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc = DecisionTreeClassifier(labelCol='stroke',featuresCol='features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Pipeline\n",
    "To wrap Spark ML stages required to train the data, we need to design pipeline as shown below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_dtc = Pipeline(stages=[gender_indexer, ever_married_indexer, work_type_indexer, Residence_type_indexer,\n",
    "                        smoking_status_indexer, hypertension_indexer, heart_disease_indexer, gender_encoder, \n",
    "                        ever_married_encoder, work_type_encoder,Residence_type_encoder, smoking_status_encoder, \n",
    "                        hypertension_encoder, heart_disease_encoder, assembler, dtc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data,test_data = train_f.randomSplit([0.7,0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dtc = pipeline_dtc.fit(train_data)\n",
    "dtc_predictions = model_dtc.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree algorithm had an accuracy of: 98.10%\n"
     ]
    }
   ],
   "source": [
    "# Select (prediction, true label) and compute test error\n",
    "acc_evaluator = MulticlassClassificationEvaluator(labelCol=\"stroke\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "dtc_acc = acc_evaluator.evaluate(dtc_predictions)\n",
    "print('Decision Tree algorithm had an accuracy of: {0:2.2f}%'.format(dtc_acc*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "categoricalColumns = ['gender', 'ever_married', 'Residence_type', 'smoking_status']\n",
    "stages = [] # stages in our Pipeline\n",
    "for categoricalCol in categoricalColumns:\n",
    "    # Category Indexing with StringIndexer\n",
    "    stringIndexer = StringIndexer(inputCol=categoricalCol, outputCol=categoricalCol + 'Index')\n",
    "    # Use OneHotEncoder to convert categorical variables into binary SparseVectors\n",
    "    # encoder = OneHotEncoderEstimator(inputCol=categoricalCol + \"Index\", outputCol=categoricalCol + \"classVec\")\n",
    "    encoder = OneHotEncoderEstimator(inputCols=[stringIndexer.getOutputCol()], outputCols=[categoricalCol + \"classVec\"])\n",
    "    # Add stages.  These are not run here, but will run all at once later on.\n",
    "    stages += [stringIndexer, encoder]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_stringIdx = StringIndexer(inputCol='stroke', outputCol='label')\n",
    "stages += [label_stringIdx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "numericCols = ['age', 'avg_glucose_level', 'bmi']\n",
    "assemblerInputs = [c + \"classVec\" for c in categoricalColumns] + numericCols\n",
    "assembler = VectorAssembler(inputCols=assemblerInputs, outputCol=\"features\")\n",
    "stages += [assembler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "partialPipeline = Pipeline().setStages(stages)\n",
    "pipelineModel = partialPipeline.fit(train_f)\n",
    "preppedDataDF = pipelineModel.transform(train_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit model to prepped data\n",
    "lrModel = LogisticRegression().fit(preppedDataDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[label: double, features: vector, id: int, gender: string, age: double, hypertension: int, heart_disease: int, ever_married: string, work_type: string, Residence_type: string, avg_glucose_level: double, bmi: double, smoking_status: string, stroke: int]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "selectedcols = [\"label\", \"features\"] + train_f.columns\n",
    "dataset = preppedDataDF.select(selectedcols)\n",
    "display(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "(trainingData, testData) = dataset.randomSplit([0.7, 0.3], seed=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LogisticRegression.transform() will only use the 'features' column.\n",
    "predictions = lrModel.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression algorithm had an accuracy of: 84.19%\n"
     ]
    }
   ],
   "source": [
    "acc_evaluator_lr = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\")\n",
    "lr_accuracy = acc_evaluator_lr.evaluate(predictions)\n",
    "print('Logistic Regression algorithm had an accuracy of: {0:2.2f}%'.format(lr_accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "float"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(lr_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "accuracy = [dtc_acc*100,lr_accuracy*100]\n",
    "models = ('Decision Tree', 'Logistic Regression')\n",
    "y_pos = np.arange(len(models))\n",
    " \n",
    "# Create bars\n",
    "plt.bar(y_pos, accuracy)\n",
    " \n",
    "# Create names on the x-axis\n",
    "plt.xticks(y_pos, models)\n",
    " \n",
    "# Show graphic\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion\n",
    "\n",
    "The Decision Tree model has an accuracy of 98 percent. But this is a skewed result. As defined earlier, the predictive model of an imbalanced dataset could provide results with misleading accuracy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remediation\n",
    "\n",
    "* Resampling: The main objective of resampling is to either increasing the frequency of the minority class or decreasing the frequency of the majority class. This is done in order to obtain approximately the same number of instances for both the classes.\n",
    "\n",
    "* Ensemble Methods: Ensemble methods improve the performance of single classifiers. The approach involves constructing several two stage classifiers from the original data and then aggregate their predictions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
